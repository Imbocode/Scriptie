from transformers import WhisperProcessor, WhisperForConditionalGeneration
from datasets import load_dataset
import tensorflow as tf
import torch
import numpy as np
import re
import librosa
from Levenshtein import distance as lev
import nltk
import os
processor = WhisperProcessor.from_pretrained("openai/whisper-small")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
model.config.forced_decoder_ids = None
WAV_DIR = "/mnt/c/Users/imbo9/Documents/wavfiles16kHz/TEST"
PHN_DIR = "mnt/c/Users/imbo9/Documents/adaptedphns"
 
list_of_wavs = []
list_of_phns = []

for file in os.listdir(WAV_DIR):
    if file.endswith(".WAV"):
        file_path = os.path.join(WAV_DIR, file)
        list_of_wavs.append(file_path)
for file in os.listdir(PHN_DIR):
    if file.endswith(".PHN"):
        file_path = os.path.join(PHN_DIR, file)
        list_of_phns.append(file_path)
list_of_phns = sorted(list_of_phns)

list_of_dr_1 = []
list_of_dr_2 = []
list_of_dr_3 = []
list_of_dr_4 = []
list_of_dr_5 = []
list_of_dr_6 = []
list_of_dr_7 = []
list_of_dr_8 = []
new_wav_list = []
for wav_file in list_of_wavs:
    dr_pattern = re.search("(DR\d)\w+[.]WAV",wav_file)
    if dr_pattern.group(1) == "DR1":
        if len(list_of_dr_1) <= 125:
            list_of_dr_1.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR2":
        if len(list_of_dr_2) <= 125:
            list_of_dr_2.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR3":
        if len(list_of_dr_3) <= 125:
            list_of_dr_3.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR4":
        if len(list_of_dr_4) <= 125:
            list_of_dr_4.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR5":
        if len(list_of_dr_5) <= 125:
            list_of_dr_5.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR6":
        if len(list_of_dr_6) <= 125:
            list_of_dr_6.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR7":
        if len(list_of_dr_7) <= 125:
            list_of_dr_7.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR8":
        if len(list_of_dr_8) <= 125:
            list_of_dr_8.append(wav_file)
            new_wav_list.append(wav_file)
list_of_sentences = []
for phn_file in list_of_phns:
    list_of_groups = []
    test_file = open(phn_file, "r")
    for line in test_file:
        pattern_list = re.findall("[a-z]+", line)
        sentence = " ".join(pattern_list)
        list_of_sentences.append(sentence)
    test_file.close()
wav_input_list = []
librosa_loads = []
for wav_file in new_wav_list: 
    dr_pattern = re.search("(DR\d)\w+[.]WAV",wav_file)
    if dr_pattern.group(1) == "DR1":
        if len(list_of_dr_1) <= 125:
            list_of_dr_1.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR2":
        if len(list_of_dr_2) <= 125:
            list_of_dr_2.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR3":
        if len(list_of_dr_3) <= 125:
            list_of_dr_3.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR4":
        if len(list_of_dr_4) <= 125:
            list_of_dr_4.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR5":
        if len(list_of_dr_5) <= 125:
            list_of_dr_5.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR6":
        if len(list_of_dr_6) <= 125:
            list_of_dr_6.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR7":
        if len(list_of_dr_7) <= 125:
            list_of_dr_7.append(wav_file)
            new_wav_list.append(wav_file)
    if dr_pattern.group(1) == "DR8":
        if len(list_of_dr_8) <= 125:
            list_of_dr_8.append(wav_file)
            new_wav_list.append(wav_file)
list_of_sentences = []
for phn_file in list_of_phns:
    list_of_groups = []
    test_file = open(phn_file, "r")
    for line in test_file:
        pattern_list = re.findall("[a-z]+", line)     
        sentence = " ".join(pattern_list)
        list_of_sentences.append(sentence)
    test_file.close()
wav_input_list = []
librosa_loads = []
for wav_file in new_wav_list: 
    speech_array, sampling_rate = librosa.load(wav_file, sr=16_000)
    librosa_loads.append(speech_array) 
test_dataset = librosa_loads
for i in range(len(test_dataset)):
    wav_input_features = processor(test_dataset[i],sampling_rate=16000,return_tensors="pt").input_features
    predicted_ids = model.generate(wav_input_features)
    predicted_sentences = processor.batch_decode(predicted_ids, skip_special_tokens=True)
    predicted_sentence = predicted_sentences[0].lower()
    print("-" * 100)
    print("Reference:", list_of_sentences[i])
    print("Prediction:", predicted_sentence)

    predicted_words = predicted_sentence.split()
    sentence_in_phones = []
    clean_arpabet_list = []
    for word in predicted_words: 
        comma_pattern = re.findall("\w+[,]+", word) 
        if len(comma_pattern) > 0:
            for comma_word in comma_pattern:
                comma_word_pattern = re.search("(\w+)[,]+",comma_word)
                word_without_comma = comma_word_pattern.group(1)
                new_word = re.sub(comma_word_pattern.group(0),word_without_comma,comma_word)
                word = new_word
        dot_pattern = re.search("(\w+)[.]+",word)
        if dot_pattern:
            word_without_dot = dot_pattern.group(1)
            word = word_without_dot
        question_mark_pattern = re.search("(\w+)\\?+",word)
        if question_mark_pattern:
            word_without_question_mark = question_mark_pattern.group(1)
            word = word_without_question_mark
        arpabet = nltk.corpus.cmudict.dict()
        try:
             word_in_phones = " ".join(arpabet[word][0])
             sentence_in_phones.append(word_in_phones)
        except Exception as e:
            print(e)
predicted_phone_sentence = " ".join(sentence_in_phones)
lower_predicted_phone_sentence = predicted_phone_sentence.lower()
phone_pattern = re.findall(" \w+", lower_predicted_phone_sentence)
phone_start_pattern = re.search("^\w+", lower_predicted_phone_sentence)
start_pattern = phone_start_pattern.group(0)
phone_pattern = [start_pattern] + phone_pattern
phone_end_pattern = re.search("\w+$", lower_predicted_phone_sentence)
end_pattern = phone_end_pattern.group(0)  
phone_pattern[-1] = end_pattern
    
for phone in phone_pattern:
    ow = re.sub("ow\d","ow",phone)
    ae = re.sub("ae\d","ae",ow)
    iy = re.sub("iy\d","iy",ae)
    uw = re.sub("uw\d","uw",iy)
    oy = re.sub("oy\d","oy",uw)
    ay = re.sub("ay\d","ay",oy)
    er = re.sub("er\d","er",ay)
    ao = re.sub("ao\d","ao",er)
    ah = re.sub("ah\d","ah",ao)
    ih = re.sub("ih\d","ih",ah)
    aw = re.sub("aw\d","aw",ih)
    uh = re.sub("uh\d","uh",aw)
    aa = re.sub("aa\d","aa",uh)
    eh = re.sub("eh\d","eh",aa)
    ey = re.sub("ey\d","ey",eh)
    ao_aa = re.sub("ao","aa",ey)
    ax_ah = re.sub("ax","ah",ao_aa)
    ax_er = re.sub("a[xh]r","er",ax_ah)
    ix_ih = re.sub("ix","ih",ax_er)
    l = re.sub("el","l",ix_ih)
    m = re.sub("em","m",l)
    en = re.sub("en","n",m)
    n = re.sub("nx","n",en)
    sh = re.sub("zh","sh",n)
    clean_phone = re.sub("ux","uw",sh)
    clean_arpabet_list.append(clean_phone)
    clean_phone_transcription = "".join(clean_arpabet_list)
    lined_clean_phone_transcription = clean_phone_transcription[:-1] + " " + clean_phone_transcription[-1]
    print("Prediction in phones:", lined_clean_phone_transcription)
    distance = lev(lined_clean_phone_transcription, list_of_sentences[i])
    print("Number of phones:", str(len(lined_clean_phone_transcription)) + " , " + 	str(len(list_of_sentences[i])))
    print(distance)
    percentage = 100 * distance/len(list_of_sentences[i])
    print(str(percentage) + "%")
